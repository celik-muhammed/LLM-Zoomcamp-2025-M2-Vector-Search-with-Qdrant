{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afbf7b4d",
   "metadata": {},
   "source": [
    "## Step 0: Setup\n",
    "\n",
    "Qdrant is fully open-source, which means you can run it in multiple ways depending on your needs.  \n",
    "You can self-host it on your own infrastructure, deploy it on Kubernetes, or run it in managed Cloud.  \n",
    "\n",
    "We're going to run a Qdrant instance in a Docker container.\n",
    "\n",
    "### Docker\n",
    "\n",
    "All you need to do is pull the image and start the container using the following commands:\n",
    "\n",
    "```bash\n",
    "docker pull qdrant/qdrant\n",
    "\n",
    "docker run -p 6333:6333 -p 6334:6334 \\\n",
    "   -v \"$(pwd)/qdrant_storage:/qdrant/storage:z\" \\\n",
    "   qdrant/qdrant\n",
    "```\n",
    "\n",
    "The second line in the `docker run` command mounts local storage to keep your data persistent.\n",
    "So even if you restart or delete the container, your data will still be stored locally.\n",
    "\n",
    "- 6333 ‚Äì REST API port\n",
    "- 6334 ‚Äì gRPC API port\n",
    "\n",
    "To help you explore your data visually, Qdrant provides a built-in **Web UI**, available in both Qdrant Cloud and local instances.\n",
    "You can use it to inspect collections, check system health, and even run simple queries.\n",
    "\n",
    "When you're running Qdrant in Docker, the Web UI is available at http://localhost:6333/dashboard\n",
    "\n",
    "### Installing Required Libraries\n",
    "\n",
    "In the environment you created specifically for this course, we‚Äôll install:\n",
    "\n",
    "- The `qdrant-client` package. We'll be using the Python client, but Qdrant also offers official clients for JavaScript/TypeScript, Go, and Rust, so you can choose the best fit for your own projects.\n",
    "\n",
    "- The `fastembed` package - an optimized embedding (data vectorization) solution designed specifically for Qdrant. Make sure you install version `>= 1.14.2` to use the **local inference** with Qdrant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fffe48b",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cf75801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jupyter ipywidgets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac54554a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (512,)\n",
      "Minimal value: -0.11726373885183883\n",
      "Vector norm: 1.0\n",
      "Cosine similarity with itself: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "import numpy as np\n",
    "\n",
    "# Initialize embedder\n",
    "embedder = TextEmbedding(\"jinaai/jina-embeddings-v2-small-en\")\n",
    "\n",
    "# Query to embed\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "\n",
    "# Get embedding (generator ‚Üí list)\n",
    "embedding = list(embedder.embed([query]))[0]\n",
    "\n",
    "# Confirm size is 512\n",
    "print(\"Embedding shape:\", embedding.shape)\n",
    "\n",
    "# Find minimal value in embedding\n",
    "min_value = np.min(embedding)\n",
    "print(\"Minimal value:\", min_value)\n",
    "\n",
    "# Check norm to verify normalization\n",
    "norm = np.linalg.norm(embedding)\n",
    "print(\"Vector norm:\", norm)\n",
    "\n",
    "# Cosine similarity with itself (dot product)\n",
    "cos_sim = embedding.dot(embedding)\n",
    "print(\"Cosine similarity with itself:\", cos_sim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b9395e",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c052da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between query and document: 0.901\n"
     ]
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "import numpy as np\n",
    "\n",
    "embedder = TextEmbedding(\"jinaai/jina-embeddings-v2-small-en\")\n",
    "\n",
    "# Embed the query\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "query_embedding = list(embedder.embed([query]))[0]\n",
    "\n",
    "# Embed the document\n",
    "doc = \"Can I still join the course after the start date?\"\n",
    "doc_embedding = list(embedder.embed([doc]))[0]\n",
    "\n",
    "# Since embeddings are normalized, cosine similarity = dot product\n",
    "cos_sim = query_embedding.dot(doc_embedding)\n",
    "\n",
    "print(f\"Cosine similarity between query and document: {cos_sim:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2bfba9",
   "metadata": {},
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b15e76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarities: [0.76296845 0.81823782 0.80853974 0.71330788 0.73044992]\n",
      "Document with highest similarity: 1\n"
     ]
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "import numpy as np\n",
    "\n",
    "# Documents data\n",
    "documents = [\n",
    "    {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\"},\n",
    "    {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.'},\n",
    "    {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  ‚ÄúOffice Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon‚Äôt forget to register in DataTalks.Club's Slack and join the channel.\"},\n",
    "    {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.'},\n",
    "    {'text': 'Star the repo! Share it with friends if you find it useful ‚ù£Ô∏è\\nCreate a PR if you see you can improve the text or the structure of the repository.'}\n",
    "]\n",
    "\n",
    "# Initialize embedder\n",
    "embedder = TextEmbedding(\"jinaai/jina-embeddings-v2-small-en\")\n",
    "\n",
    "# Query\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "query_embedding = list(embedder.embed([query]))[0]\n",
    "\n",
    "# Embed all documents\n",
    "doc_texts = [doc['text'] for doc in documents]\n",
    "doc_embeddings = list(embedder.embed(doc_texts))  # list of numpy arrays\n",
    "\n",
    "# Stack embeddings into matrix V (shape: number_of_docs x 512)\n",
    "V = np.stack(doc_embeddings)  # shape (5, 512)\n",
    "\n",
    "# Compute cosine similarity = dot product (because normalized)\n",
    "cosine_similarities = V.dot(query_embedding)  # shape (5,)\n",
    "\n",
    "print(\"Cosine similarities:\", cosine_similarities)\n",
    "\n",
    "# Find the index of the highest similarity\n",
    "best_doc_index = np.argmax(cosine_similarities)\n",
    "print(\"Document with highest similarity:\", best_doc_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8554ac",
   "metadata": {},
   "source": [
    "### Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a298916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0: Cosine similarity = 0.8592\n",
      "Document 1: Cosine similarity = 0.8474\n",
      "Document 2: Cosine similarity = 0.8226\n",
      "Document 3: Cosine similarity = 0.8021\n",
      "Document 4: Cosine similarity = 0.8345\n",
      "\n",
      "üîç Best matching document index (Q4): 0\n"
     ]
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "import numpy as np\n",
    "\n",
    "# Query\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "\n",
    "# Documents\n",
    "documents = [\n",
    "    {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines...\",\n",
    "     'question': 'Course - Can I still join the course after the start date?'},\n",
    "    {'text': 'Yes, we will keep all the materials after the course finishes...',\n",
    "     'question': 'Course - Can I follow the course after it finishes?'},\n",
    "    {'text': \"The purpose of this document is to capture frequently asked technical questions...\",\n",
    "     'question': 'Course - When will the course start?'},\n",
    "    {'text': 'You can start by installing and setting up all the dependencies and requirements...',\n",
    "     'question': 'Course - What can I do before the course starts?'},\n",
    "    {'text': 'Star the repo! Share it with friends if you find it useful ‚ù£Ô∏è...',\n",
    "     'question': 'How can we contribute to the course?'}\n",
    "]\n",
    "\n",
    "# Initialize embedder\n",
    "embedder = TextEmbedding(\"jinaai/jina-embeddings-v2-small-en\")\n",
    "\n",
    "# Embed the query\n",
    "query_embedding = list(embedder.embed([query]))[0]\n",
    "\n",
    "# Concatenate question + text\n",
    "full_texts = [doc['question'] + ' ' + doc['text'] for doc in documents]\n",
    "\n",
    "# Embed concatenated texts\n",
    "full_embeddings = list(embedder.embed(full_texts))\n",
    "V_full = np.stack(full_embeddings)  # shape (5, 512)\n",
    "\n",
    "# Compute cosine similarities (dot product, since embeddings are normalized)\n",
    "cos_sims = V_full.dot(query_embedding)\n",
    "\n",
    "# Output similarities\n",
    "for idx, score in enumerate(cos_sims):\n",
    "    print(f\"Document {idx}: Cosine similarity = {score:.4f}\")\n",
    "\n",
    "# Find best document\n",
    "best_index = int(np.argmax(cos_sims))\n",
    "print(f\"\\nüîç Best matching document index (Q4): {best_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33e7a57",
   "metadata": {},
   "source": [
    "### Q5\n",
    "\n",
    "- https://huggingface.co/BAAI/bge-small-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12b212e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (384,)\n"
     ]
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "import numpy as np\n",
    "\n",
    "# Load the small model\n",
    "embedder = TextEmbedding(\"BAAI/bge-small-en\")\n",
    "\n",
    "# Sample sentence\n",
    "sample = \"This is a test sentence.\"\n",
    "\n",
    "# Embed and check dimensionality\n",
    "embedding = list(embedder.embed([sample]))[0]\n",
    "print(\"Embedding shape:\", embedding.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8e9a1e",
   "metadata": {},
   "source": [
    "### Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "823cf427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install qdrant-client fastembed -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f9ca8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "documents_raw = requests.get(docs_url).json()\n",
    "\n",
    "documents = []\n",
    "for course in documents_raw:\n",
    "    if course['course'] != 'machine-learning-zoomcamp':\n",
    "        continue\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course['course']\n",
    "        documents.append(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e54d0bf",
   "metadata": {},
   "source": [
    "#### Prepare embeddings with BAAI/bge-small-en (128-dim):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4afbde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed import TextEmbedding\n",
    "from uuid import uuid4\n",
    "\n",
    "# Embedder\n",
    "embedder = TextEmbedding(\"BAAI/bge-small-en\")\n",
    "\n",
    "# Prepare (id, payload, vector)\n",
    "records = []\n",
    "for doc in documents:\n",
    "    full_text = doc['question'] + ' ' + doc['text']\n",
    "    embedding = list(embedder.embed([full_text]))[0]\n",
    "    records.append({\n",
    "        \"id\": str(uuid4()),\n",
    "        \"vector\": embedding,\n",
    "        \"payload\": {\n",
    "            \"question\": doc['question'],\n",
    "            \"text\": doc['text'],\n",
    "            \"course\": doc['course']\n",
    "        }\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b1c51c",
   "metadata": {},
   "source": [
    "#### Upload to Qdrant (local instance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "122950e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14949/3974796530.py:9: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "\n",
    "client = QdrantClient(\"http://localhost:6333\")  # or use QdrantCloud\n",
    "\n",
    "collection_name = \"ml-faq\"\n",
    "\n",
    "# Create collection\n",
    "client.recreate_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE),\n",
    ")\n",
    "\n",
    "# Upload records\n",
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=records\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658b1534",
   "metadata": {},
   "source": [
    "#### Query with Q1 question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "481753c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest similarity score: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14949/2013297386.py:4: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result = client.search(\n"
     ]
    }
   ],
   "source": [
    "query = \"I just discovered the course. Can I join now?\"\n",
    "query_vector = list(embedder.embed([query]))[0]\n",
    "\n",
    "search_result = client.search(\n",
    "    collection_name=collection_name,\n",
    "    query_vector=query_vector,\n",
    "    limit=1,\n",
    ")\n",
    "\n",
    "# Print highest score\n",
    "print(f\"Highest similarity score: {search_result[0].score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6423d36a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
